# Goal-oriented-Dialog-System --- Datasets/ Dialog State Tracking/ Policy/ Response Generation

## 1 Datasets

## 2 Dialog State Tracking

## 3 Policy & Dialog Management

### 1 Deep Reinforcement Learning

**[1]** Milica Gasic, C. Breslin, M. Henderson, D. Kim, M. Szummer, B. Thomson, P. Tsiakoulis and Steve Young 
**POMDP-based dialogue manager adaptation to extended domains**
SigDial 2013  **[GPRL]**   

**[2]** Milica Gasic and Steve Young. 
**Gaussian processes for pomdp-based dialogue manager optimization.**
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2014 **[GPRL]**

**[3]** Milica Gasic, Nikola Mrksic, Pei-Hao Su, David Vandyke, Tsung-Hsien Wen, and Steve Young.
**Policy committee for adaptation in multi-domain spoken dialogue systems.**
ASRU 2015 **[BCM]**

**[4]** Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas- Barahona, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, and Steve Young.  
**Continuously learning neural dialogue management.**
arXiv 2016

**[5]** Pei-Hao Su, PaweÅ‚ Budzianowski, Stefan Ultes, Milica Gasic, and Steve Young 
**Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management**
SigDial 2017

**[6]** Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas-Barahona, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, and Steve Young. 
**On-line active reward learning for policy optimisation in spoken dialogue systems.**
ACL 2016
1. The dialogue success is modeledâ€¨using Gaussian Process
2. If the reward model is uncertain, user feedback is required; otherwise the predicted success rate is utilized.

**[7]** Bing Liu, Ian Lane
**Iterative Policy Learning in End-to-End Trainable Task-Oriented Neural Dialog Models**
ASRU 2017

**[8]** Baolin Peng, Xiujun Li, Jianfeng Gao, Jingjing Liu, Yun-Nung Chen, and Kam-Fai Wong. 
**Adversarial advantage actor-critic model for task-completion dialogue policy learning.** 
arXiv 2017.

**[9]** Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, and Li Deng.
**Towards end-to-end reinforcement learning of dialogue agents for information access.**
ACL 2017

**[10]** Pararth Shah, Dilek Hakkani-Tur, Bing Liu, Gokhan Tur
**Bootstrapping a Neural Conversational Agent with Dialogue Self-Play, Crowdsourcing and On-Line Reinforcement Learning**
NAACL 2018

**[11]** Zachary Lipton, Xiujun Li, Jianfeng Gao, Lihong Li, Faisal Ahmed, Li Deng
**BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems**
AAAI 2018
1. BBQ maintains an distribution q over the parameters to estimate their uncertainty. 
2. Use Thompson Sampling to select actions based on the probability distribution.

**[12]** Baolin Peng Xiujun Li Jianfeng Gao Jingjing Liu Kam-Fai Wong Shang-Yu Su
**Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning**
ACL 2018 **[DDQ]**
1. Train the policy and simulator jointly
2. The â€œworld modelâ€ is actually a simulator


**[13]** Shang-Yu Su Xiujun Li Jianfeng Gao Jingjing Liu Yun-Nung Chen
**D3Q: Robust Planning for Dialogue Policy Learning**
EMNLP 2018 **[D3Q]**
1. Applying a discriminator to identify whether an experience is from simulator or real user
2. In the simulation stage, repeat simulation until ğ¾ high quality experiences are collected


**[14]** Yuexin Wu, Xiujun Li, Jingjing Liu, Jianfeng Gao, Yiming Yang
**Switch-based Active Deep Dyna-Q: Efficient Adaptive Planning for Task-Completion Dialogue Policy Learning**
AAAI 2019 **[Switch-DDQ]**
1. Train a score function ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’() to measure the quality of simulated experience (Similar to the discriminator in D3Q)

2. Select the user goal based on validation accuracy (Goals with lower success rate are of higher priority)


**[15]** Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang
**Personalizing a Dialogue System with Transfer Reinforcement Learning**
AAAI 2018
1. The dialogue policy of a user can be decomposed to a general and a user-specific policy.
2. Learning general policy from source data (large), and user-specific policy with target data (small).

**[16]** Vladimir Ilievski, Claudiu Musat, Andreea Hossmann, Michael Baeriswyl
**Goal-Oriented Chatbot Dialog Management Bootstrapping with Transfer Learning**
IJCAI 2018 **[done by my colleague]**
1. Similar domains share some common slots.
2. After training in target domain, the parameters of common slots can be copied to source model.
3. Experiment done on two domains (Restaurant and Movie)




### 2 Multi-domain/Composite-task Dialogues

**[1]** Milica Gasic, C. Breslin, M. Henderson, D. Kim, M. Szummer, B. Thomson, P. Tsiakoulis and Steve Young 
**POMDP-based dialogue manager adaptation to extended domains**
SigDial 2013 Best Paper 

**[2]** Milica Gasic, Nikola Mrksic, Pei-hao Su, David Vandyke, Tsung-Hsien Wen, and Steve Young
**Policy committee for adaptation in multi-domain spoken dialogue systems**
ASRU2015
1. Some policies are firstly trained on different datasets.
2. All policies recommend an action, which are then aggregated into a final action by the BCM policy.


**[3]** Zhuoran Wang, Yannis Stylianou, Tsung-Hsien Wen, Pei-Hao Su, Steve Young
**Learning Domain-Independent Dialogue Policies via Ontology Parameterisation**
SigDial 2015
1. äººå·¥åŸºäºä¸åŒdomainçš„ontologyå®šä¹‰äº† **å¾ˆå¤šå¾ˆå¤š** domain-invariant featureå–‚åˆ°policyçš„stateè¡¨ç¤ºé‡Œï¼Œæ–‡ä¸­å«Domain Independent Parametrisation (DIP)
2. è¿™ç¯‡æ˜¯åŸºäº **[1]** çš„é«˜æ–¯è¿‡ç¨‹POMDPï¼Œ åé¢ **[6,10]** åŠ å…¥DeepRLï¼Œè¿™ç±»æ–¹æ³•åƒæ˜¯transfer learning

**[4]** Heriberto CuayaÌhuitl, Seunghak Yu, Ashley Williamson, Jacob Carse
**Deep Reinforcement Learning for Multi-Domain Dialogue Systems**
NIPS 2016 RL workshop
1. model domain transition by a deterministic F, F is trained with MLP+SVM.
2. EMNLP2017â€™çš„HRLå’Œè¿™ä¸ªæ€è·¯ç›¸ä¼¼ï¼Œä¸è¿‡domain transitionæ˜¯é€šè¿‡top-level policyå­¦å¾—
3. æœ¬æ–‡åé¢å‘åœ¨IJCNN2017 **[5]**

**[5]** Heriberto CuayÃ¡huitl, Seunghak Yu Ashley Williamson, Jacob Carse
**Scaling Up Deep Reinforcement Learning for Multi-Domain Dialogue Systems**
IJCNN 2017

**[6]** Alexandros Papangelis and Yannis Stylianou
**Single-Model Multi-domain Dialogue Management with Deep Learning**
IWSDS 2017
1. propose DIP **[3]** + DQN
2. ç›´æ¥å§Deep Q Learningä¸­çš„stateæ¢æˆäº†DIPè¡¨ç¤ºï¼Œæ‰€ä»¥å¯ä»¥domain independent

**[7]** Alexandros Papangelis, Stefan Ultes and Yannis Stylianou
**Domain Complexity and Policy Learning in Task-Oriented Dialogue Systems**
IWSDS 2017

1. æ¯”è¾ƒæœ€æ™®é€šçš„GPRLå’ŒDQNåœ¨ä¸åŒçš„domainçš„æ•ˆç‡

**[8]** Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin Lee, and Kam-Fai Wong. 
**Composite task-completion dialogue policy learning via hierarchical deep reinforcement learning.**
EMNLP 2017
1. æå‡ºäº†temporal HRL to model temporal transition between subtasks. ä¼˜åŒ–DQN å®šä¹‰äº†æ¯ä¸ªsubtaskçš„intrinsic rewardï¼Œè¡¨ç¤ºè¯¥å­ä»»åŠ¡çš„å®Œæˆåº¦
2. æåˆ°äº†slot constraints among subtasksçš„æ¦‚å¿µï¼Œå¹¶ä¸”é€šè¿‡åœ¨user simulationä¸­åŠ å…¥constraintsï¼Œè®©HRLå»å­¦ã€‚user simulationæ˜¯FRAMES+Constraints

**[9]** Pawel Budzianowski, Stefan Ultes, Pei-Hao Su, Nikola Mrksic, Tsung-Hsien Wen, Inigo Casanueva, Lina Rojas-Barahona, and Milica Gasic.
**Sub-domain modelling for dialogue management with hierarchical reinforcement learning.** 
arXiv 2017

1. å’Œ **[8]** ç±»ä¼¼ï¼Œä¹Ÿæ˜¯model HRLï¼Œä½†æ˜¯Q functionæ˜¯ç”¨çš„ **[1]** ä¸­çš„Gaussian Processå»ä¼°è®¡çš„ã€‚

**[10]** 
Inigo Casanueva, PaweÅ‚ Budzianowski,Pei-Hao Su, Stefan Ultes, Lina Rojas-Barahona, Bo-Hsiang Tseng, and Milica Gasic
**Feudal Reinforcement Learning for Dialogue Management in Large Domains**
NAACL 2018
1. æœ¬æ–‡åŸºäºDIP **[3]** çš„domain-independentç‰¹å¾è¡¨ç¤ºï¼Œæå‡ºFeudal RLã€‚ å…¶æœ¬è´¨ä¹Ÿæ˜¯ä¸€ç§HRLï¼Œä¸è¿‡å¾®è½¯çš„HRL **[8]** æ˜¯åŸºäºå®šä¹‰å¥½çš„temporal subtasksï¼Œæœ¬æ–‡åªè€ƒè™‘æ˜¯å¦å’Œslotç›¸å…³ï¼Œä¸å®šä¹‰tasks. å…ˆæ ¹æ®stateé€‰act_type, if it's slot-independent -> è·³Q^i else è·³Q^s é€‰<s,v>ã€‚æ‰€ä»¥å¾®è½¯çš„HRLæ˜¯temporalï¼Œæœ¬æ–‡æ˜¯spatial ï¼ï¼ï¼
2. information sharing mechanism between slotsï¼šQ^s policyçš„å‚æ•°å¯¹ä¸åŒçš„slotå…±äº«
3. å®éªŒä¸­çš„æ¯”äº† **[6]** ï¼Œ è¯æ˜FDQNæ¯”æ™®é€šDNQå¥½ï¼Œæ²¡æ¯” **[8]**


## 2 Other Papers



